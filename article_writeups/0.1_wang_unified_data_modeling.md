# Reflection on [Unified Data Modeling for Relational and NoSQL Databases](https://www.infoq.com/articles/unified-data-modeling-for-relational-and-nosql-databases/)

#### Author: Allen Wang
#### Published by InfoQ, 2016

Allen Wang's article lays out the case for managing enterprise-scale data in a unified manner, as the applications that produce and consume that data increasingly use both relational and NoSQL data sources. Although this piece is written from the standpoint of recommending a specific product, CA ERwin, Wang still makes many points and raises questions relevant to the wider topic.

Wang begins by noting the strengths and weaknesses of traditional, relational DB’s and NoSQL DB’s. He also points out that the emphasis of NoSQL is more on application performance, and less on business models, data integration, and data standardization. He noted that there was still a gap between data modeling and the physical storage of data in NoSQL systems, but that a data model is key to ensure that data architecture meets business requirements.

The specific tool that Wang recommends is suited to work with relational, document store, and column store databases (examples of the latter two are MongoDB and HBase). It allows users to build a “unified” data model, and then forward or reverse engineer database implementations or facilitate data migration.

He starts by explaining the conceptual / logical model that underpins the universal modeling, which consists of:

* Entities
* Properties
* Relationships
* Tags

These elements of the logical model map to features of both relational and NoSQL data models. For example:

* **Entity** corresponds with a table (relational, r.), a collection (document, d.) or a column family (column store, c.)
* **Entity instance** corresponds to a table row (r.), a document (d.), or a row (c.)
* **Relationship** corresponds to a constraint (r.), a reference or embedded document (d.), or a row across column families (c.)

Beyond the logical model, this unified modeling approach also relies on query patterns and production patterns. Query patterns describe *how* users will access or work with the data, and include aspects such as aggregation, n-to-n relationships, and frequent queries. Production patterns describe the physical character of the databases, such as the volume of data to be stored and whether an entity needs strong consistency or eventual consistency. These patterns help determine how to transform the logical model into a physical model implemented within the target database. For example, an entity that requires strong consistency would not be embedded within other entities under the document or column store paradigms. Frequently queried properties may warrant an index. Wang provides an illustrative example of these ideas as applied to a database for movies.

It was interesting to read this article to gain a high-level view of the sorts of problems that arise when developing a large application that uses heterogeneous data stores. I would guess that the piece is targeted to architects or engineers who know that the application they’re working on will benefit from a polyglot persistence approach, but also want to make sure the different data stores are accessible and interoperable. In this way, I felt like I got a glimpse into the concerns and considerations that would be churning around the heads of such individuals.

I also appreciated getting a broad look at the strategies one solution brings to the table to tackle the problem. It quickly became apparent that the goal was to step “one level above” the existing database solutions and identify commonalities between each. This seemed to drive the adoption of the offered “logical model”, so that different elements of different database paradigms could all map to a single element in this universal logical model. Intuitively, this would have to be the first step to any solution for bridging the gaps in a polyglot persistence system: describing everything in a common language, to tell what elements from one system correspond to in another system.

I hadn’t previously considered how actual aspects of accumulating and accessing the data (the “query patterns” and “production patterns”) would bear on making a universal model for disparate data stores; it was interesting to see the article discuss that a little. I’m starting to see that it’s not only a matter of mapping elements or concepts from one system to another, but also accounting for how those systems allow data access, modification, and querying.

While this was a good read to get me thinking about the concepts, I was still a little disappointed by the fact that the unified data model tool discussed did not account for graph data, the lack of in-depth information on how the tool operates, and any sort of demonstration of the outcome of using the tool. I’m hoping that some of the readings in the future will cover a broader spectrum of data storage paradigms and get into finer details around how the different stores in a polyglot system can be unified by a single model, and what implications that might have when applied to an application.